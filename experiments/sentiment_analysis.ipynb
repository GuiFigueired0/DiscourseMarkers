{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sentiment Analysis",
   "id": "f2c72394301c57cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "b0f367c2338ceafe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:00.544086Z",
     "start_time": "2025-11-10T12:12:55.584737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "import os\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ],
   "id": "5de787727c527e1c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "be66f52a90647572"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:01.698347Z",
     "start_time": "2025-11-10T12:13:01.694870Z"
    }
   },
   "cell_type": "code",
   "source": "DATASET_ID = \"imdb\"",
   "id": "3dc0ef1771919676",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:06.729688Z",
     "start_time": "2025-11-10T12:13:02.561392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(DATASET_ID)\n",
    "\n",
    "val_test_split = dataset['test'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "raw_train = dataset['train']\n",
    "raw_val = val_test_split['test']\n",
    "raw_test = val_test_split['train']\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'text': raw_test['text'],\n",
    "    'label': raw_test['label']\n",
    "})\n",
    "\n",
    "print(f\"Train samples: {len(raw_train)}\")\n",
    "print(f\"Validation samples: {len(raw_val)}\")\n",
    "print(f\"Test samples: {len(raw_test)}\")"
   ],
   "id": "6d58de86d53e5984",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 25000\n",
      "Validation samples: 5000\n",
      "Test samples: 20000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:06.835198Z",
     "start_time": "2025-11-10T12:13:06.830232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_names = raw_train.features['label'].names\n",
    "num_labels = len(class_names)\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "label2id = {label: i for i, label in enumerate(class_names)}\n",
    "\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "print(f\"The labels: {class_names}\") # -> ['neg', 'pos']"
   ],
   "id": "11d6258baf89f2f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 2\n",
      "The labels: ['neg', 'pos']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Metrics",
   "id": "269bb07a8faf09f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:10.358922Z",
     "start_time": "2025-11-10T12:13:06.922366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metric_f1 = evaluate.load(\"f1\")\n",
    "metric_accuracy = evaluate.load(\"accuracy\")\n",
    "metric_precision = evaluate.load(\"precision\")\n",
    "metric_recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    f1_weighted = metric_f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    f1_macro = metric_f1.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    accuracy = metric_accuracy.compute(predictions=predictions, references=labels)\n",
    "    precision = metric_precision.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    recall = metric_recall.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"f1_weighted\": f1_weighted[\"f1\"],\n",
    "        \"f1_macro\": f1_macro[\"f1\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "    }"
   ],
   "id": "9e607c22d844abb2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Case 1",
   "id": "af10ba7b18ada1c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Config",
   "id": "8c00540c55809dda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T08:55:59.901795Z",
     "start_time": "2025-11-10T08:55:59.897531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_ID_CASE_1 = 'roberta-base'\n",
    "REPOSITORY_ID_CASE_1 = os.path.join('models', f\"{MODEL_ID_CASE_1}-finetuned-{DATASET_ID}\")"
   ],
   "id": "985145ee3537fb8f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pre-processing",
   "id": "4f595744c2976682"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T08:56:00.512173Z",
     "start_time": "2025-11-10T08:55:59.952599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_ID_CASE_1)\n",
    "\n",
    "def tokenize(batch):\n",
    "    # 'imdb' uses the column 'text'\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False\n",
    "    )"
   ],
   "id": "59d17a8e16160d76",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T08:56:11.704432Z",
     "start_time": "2025-11-10T08:56:00.526222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_train = raw_train.map(tokenize, batched=True)\n",
    "tokenized_val = raw_val.map(tokenize, batched=True)\n",
    "tokenized_test = raw_test.map(tokenize, batched=True)"
   ],
   "id": "504d991dfad38d7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fed6a0a0efef439aacb841f796c55fc8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15deacbc405642819dd652065d093aa9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "259dbf76447c4a95a750fa3bd21fb9e9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T08:56:11.794044Z",
     "start_time": "2025-11-10T08:56:11.789521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_to_keep = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "tokenized_train.set_format(\"torch\", columns=columns_to_keep)\n",
    "tokenized_val.set_format(\"torch\", columns=columns_to_keep)\n",
    "tokenized_test.set_format(\"torch\", columns=columns_to_keep)"
   ],
   "id": "e6af7c6eb08ba0f0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "a6788de553553c01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T08:56:12.070329Z",
     "start_time": "2025-11-10T08:56:11.850718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_1 = AutoConfig.from_pretrained(MODEL_ID_CASE_1)\n",
    "config_1.update({\"id2label\": id2label, \"label2id\": label2id})\n",
    "model_1 = RobertaForSequenceClassification.from_pretrained(MODEL_ID_CASE_1, config=config_1)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "id": "7c69fe132b1ee6d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "train: 25k / 32 ~ 780 steps per epoch",
   "id": "47e01879c4e96f09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T08:56:12.311264Z",
     "start_time": "2025-11-10T08:56:12.084174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args_1 = TrainingArguments(\n",
    "    output_dir=REPOSITORY_ID_CASE_1,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=150,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=150,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=150,\n",
    "    logging_dir=os.path.join(REPOSITORY_ID_CASE_1, 'logs'),\n",
    "\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"tensorboard\",\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    ")"
   ],
   "id": "49e8375f4f4c1d71",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T08:56:12.524882Z",
     "start_time": "2025-11-10T08:56:12.324979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_1 = Trainer(\n",
    "    model=model_1,\n",
    "    args=training_args_1,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ],
   "id": "34c23f5aa28a95dc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "fe8b632310684f82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:24:25.949251Z",
     "start_time": "2025-11-10T08:56:12.538006Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_1.train()",
   "id": "2f9896a43a1b9475",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2700' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2700/7820 28:12 < 53:31, 1.59 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>0.311236</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.911769</td>\n",
       "      <td>0.911758</td>\n",
       "      <td>0.916142</td>\n",
       "      <td>0.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>0.205298</td>\n",
       "      <td>0.931200</td>\n",
       "      <td>0.931154</td>\n",
       "      <td>0.931158</td>\n",
       "      <td>0.932489</td>\n",
       "      <td>0.931200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>0.318356</td>\n",
       "      <td>0.897600</td>\n",
       "      <td>0.896837</td>\n",
       "      <td>0.896815</td>\n",
       "      <td>0.909342</td>\n",
       "      <td>0.897600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.161162</td>\n",
       "      <td>0.938800</td>\n",
       "      <td>0.938793</td>\n",
       "      <td>0.938794</td>\n",
       "      <td>0.939056</td>\n",
       "      <td>0.938800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.313417</td>\n",
       "      <td>0.928200</td>\n",
       "      <td>0.928060</td>\n",
       "      <td>0.928052</td>\n",
       "      <td>0.931377</td>\n",
       "      <td>0.928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.205842</td>\n",
       "      <td>0.938600</td>\n",
       "      <td>0.938533</td>\n",
       "      <td>0.938528</td>\n",
       "      <td>0.940372</td>\n",
       "      <td>0.938600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.172806</td>\n",
       "      <td>0.943400</td>\n",
       "      <td>0.943382</td>\n",
       "      <td>0.943380</td>\n",
       "      <td>0.943885</td>\n",
       "      <td>0.943400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.160895</td>\n",
       "      <td>0.947000</td>\n",
       "      <td>0.946999</td>\n",
       "      <td>0.946998</td>\n",
       "      <td>0.947030</td>\n",
       "      <td>0.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.237048</td>\n",
       "      <td>0.942200</td>\n",
       "      <td>0.942198</td>\n",
       "      <td>0.942198</td>\n",
       "      <td>0.942310</td>\n",
       "      <td>0.942200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.158706</td>\n",
       "      <td>0.946400</td>\n",
       "      <td>0.946399</td>\n",
       "      <td>0.946398</td>\n",
       "      <td>0.946422</td>\n",
       "      <td>0.946400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.240733</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.936908</td>\n",
       "      <td>0.936902</td>\n",
       "      <td>0.939396</td>\n",
       "      <td>0.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.217943</td>\n",
       "      <td>0.946400</td>\n",
       "      <td>0.946379</td>\n",
       "      <td>0.946376</td>\n",
       "      <td>0.947027</td>\n",
       "      <td>0.946400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.182507</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>0.949199</td>\n",
       "      <td>0.949199</td>\n",
       "      <td>0.949213</td>\n",
       "      <td>0.949200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.227065</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.943755</td>\n",
       "      <td>0.943751</td>\n",
       "      <td>0.945091</td>\n",
       "      <td>0.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.226409</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.944993</td>\n",
       "      <td>0.944992</td>\n",
       "      <td>0.945168</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.213099</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.275270</td>\n",
       "      <td>0.945200</td>\n",
       "      <td>0.945200</td>\n",
       "      <td>0.945200</td>\n",
       "      <td>0.945203</td>\n",
       "      <td>0.945200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.268483</td>\n",
       "      <td>0.947600</td>\n",
       "      <td>0.947600</td>\n",
       "      <td>0.947600</td>\n",
       "      <td>0.947600</td>\n",
       "      <td>0.947600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "a9fa2a1e07fe60d798a13af965dd83db"
     }
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2700, training_loss=0.1568860771037914, metrics={'train_runtime': 1693.1032, 'train_samples_per_second': 147.658, 'train_steps_per_second': 4.619, 'total_flos': 2.269744374615024e+16, 'train_loss': 0.1568860771037914, 'epoch': 3.452685421994885})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate",
   "id": "9cbafd49ce7f383"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:26:03.376270Z",
     "start_time": "2025-11-10T09:24:26.231284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_predictions_1 = trainer_1.predict(tokenized_test)\n",
    "\n",
    "y_pred_1 = np.argmax(test_predictions_1.predictions, axis=-1)\n",
    "\n",
    "print(\"Test Set Metrics - Case 1 (Baseline):\")\n",
    "print(test_predictions_1.metrics)"
   ],
   "id": "814b354aaef09503",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "b0a31851aaf08fc0f3d4f27972adee5b"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Metrics - Case 1 (Baseline):\n",
      "{'test_loss': 0.18828286230564117, 'test_accuracy': 0.9469, 'test_f1_weighted': 0.946899558203476, 'test_f1_macro': 0.946899456250432, 'test_precision': 0.9469119189049521, 'test_recall': 0.9469, 'test_runtime': 97.1362, 'test_samples_per_second': 205.896, 'test_steps_per_second': 6.434}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:26:03.565353Z",
     "start_time": "2025-11-10T09:26:03.559890Z"
    }
   },
   "cell_type": "code",
   "source": "df_results['case_1_pred'] = y_pred_1",
   "id": "299f618e5e30b5be",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:28:12.310773Z",
     "start_time": "2025-11-10T09:28:11.837455Z"
    }
   },
   "cell_type": "code",
   "source": "df_results.to_csv('experiment_results.csv', index=False)",
   "id": "f9009b4574d5666c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  case_1_pred  \\\n",
      "0  I found it real shocking at first to see Willi...      1            1   \n",
      "1  it's a great movie for the whole family. i don...      1            1   \n",
      "2  This movie is not a remake of She's all That (...      0            0   \n",
      "3  Believe me I wanted this series to work, but t...      1            0   \n",
      "4  It's not a movie, but an experience!<br /><br ...      1            1   \n",
      "\n",
      "  label_name case_1_pred_name  \n",
      "0        pos              pos  \n",
      "1        pos              pos  \n",
      "2        neg              neg  \n",
      "3        pos              neg  \n",
      "4        pos              pos  \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Case 2",
   "id": "79cb975f89b40989"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Config",
   "id": "99840b674d4a832e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:28:27.127484Z",
     "start_time": "2025-11-10T09:28:27.123860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_ID_CASE_2 = \"./models/roberta-base-dm-4class\"\n",
    "REPOSITORY_ID_CASE_2 = f\"./models/roberta-dm-finetuned-{DATASET_ID}\""
   ],
   "id": "6ecec017c8b88588",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pre-processing",
   "id": "26878ee4eb632d88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:28:30.320886Z",
     "start_time": "2025-11-10T09:28:30.194242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_ID_CASE_2)\n",
    "\n",
    "def tokenize(batch):\n",
    "    # 'imdb' uses the column 'text'\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False\n",
    "    )"
   ],
   "id": "9645025e9423febf",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:28:30.712237Z",
     "start_time": "2025-11-10T09:28:30.627742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_train = raw_train.map(tokenize, batched=True)\n",
    "tokenized_val = raw_val.map(tokenize, batched=True)\n",
    "tokenized_test = raw_test.map(tokenize, batched=True)\n",
    "\n",
    "columns_to_keep = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "tokenized_train.set_format(\"torch\", columns=columns_to_keep)\n",
    "tokenized_val.set_format(\"torch\", columns=columns_to_keep)\n",
    "tokenized_test.set_format(\"torch\", columns=columns_to_keep)"
   ],
   "id": "9cc9ae8aa40db0f5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "193aada414578c85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:28:37.021276Z",
     "start_time": "2025-11-10T09:28:36.935336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_2 = AutoConfig.from_pretrained(MODEL_ID_CASE_2)\n",
    "config_2.update({\"id2label\": id2label, \"label2id\": label2id, \"num_labels\": num_labels})\n",
    "model_2 = RobertaForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID_CASE_2,\n",
    "    config=config_2,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "id": "346863be9b8b411f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./models/roberta-base-dm-4class and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([4, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "train: 25k / 32 ~ 780 steps per epoch",
   "id": "212a9f39e6e2f19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:28:39.870481Z",
     "start_time": "2025-11-10T09:28:39.845621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args_2 = TrainingArguments(\n",
    "    output_dir=REPOSITORY_ID_CASE_2,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=150,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=150,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=150,\n",
    "    logging_dir=f\"{REPOSITORY_ID_CASE_2}/logs\",\n",
    "\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"tensorboard\",\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    ")"
   ],
   "id": "bc0d15f615a2aa2b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:28:41.316377Z",
     "start_time": "2025-11-10T09:28:41.170582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_2 = Trainer(\n",
    "    model=model_2,\n",
    "    args=training_args_2,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ],
   "id": "40e69f820aef9d3d",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "3c043987b17f7dff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:53:53.734941Z",
     "start_time": "2025-11-10T09:28:42.684679Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_2.train()",
   "id": "53fe4019c755553e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2400' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2400/7820 25:10 < 56:53, 1.59 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.216524</td>\n",
       "      <td>0.923600</td>\n",
       "      <td>0.923582</td>\n",
       "      <td>0.923579</td>\n",
       "      <td>0.923927</td>\n",
       "      <td>0.923600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.197645</td>\n",
       "      <td>0.924600</td>\n",
       "      <td>0.924422</td>\n",
       "      <td>0.924413</td>\n",
       "      <td>0.928435</td>\n",
       "      <td>0.924600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.243134</td>\n",
       "      <td>0.916800</td>\n",
       "      <td>0.916471</td>\n",
       "      <td>0.916458</td>\n",
       "      <td>0.923203</td>\n",
       "      <td>0.916800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.165756</td>\n",
       "      <td>0.941800</td>\n",
       "      <td>0.941795</td>\n",
       "      <td>0.941794</td>\n",
       "      <td>0.941905</td>\n",
       "      <td>0.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.188752</td>\n",
       "      <td>0.935800</td>\n",
       "      <td>0.935741</td>\n",
       "      <td>0.935737</td>\n",
       "      <td>0.937262</td>\n",
       "      <td>0.935800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.205042</td>\n",
       "      <td>0.939200</td>\n",
       "      <td>0.939183</td>\n",
       "      <td>0.939185</td>\n",
       "      <td>0.939775</td>\n",
       "      <td>0.939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.159611</td>\n",
       "      <td>0.937600</td>\n",
       "      <td>0.937576</td>\n",
       "      <td>0.937579</td>\n",
       "      <td>0.938365</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.171073</td>\n",
       "      <td>0.943000</td>\n",
       "      <td>0.942976</td>\n",
       "      <td>0.942973</td>\n",
       "      <td>0.943663</td>\n",
       "      <td>0.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.169473</td>\n",
       "      <td>0.946200</td>\n",
       "      <td>0.946194</td>\n",
       "      <td>0.946195</td>\n",
       "      <td>0.946452</td>\n",
       "      <td>0.946200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.185406</td>\n",
       "      <td>0.937200</td>\n",
       "      <td>0.937145</td>\n",
       "      <td>0.937140</td>\n",
       "      <td>0.938607</td>\n",
       "      <td>0.937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.219211</td>\n",
       "      <td>0.947200</td>\n",
       "      <td>0.947191</td>\n",
       "      <td>0.947189</td>\n",
       "      <td>0.947455</td>\n",
       "      <td>0.947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.218490</td>\n",
       "      <td>0.946200</td>\n",
       "      <td>0.946190</td>\n",
       "      <td>0.946188</td>\n",
       "      <td>0.946480</td>\n",
       "      <td>0.946200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.236652</td>\n",
       "      <td>0.943200</td>\n",
       "      <td>0.943190</td>\n",
       "      <td>0.943191</td>\n",
       "      <td>0.943593</td>\n",
       "      <td>0.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.218229</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.941996</td>\n",
       "      <td>0.941995</td>\n",
       "      <td>0.942090</td>\n",
       "      <td>0.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.279793</td>\n",
       "      <td>0.939000</td>\n",
       "      <td>0.938944</td>\n",
       "      <td>0.938940</td>\n",
       "      <td>0.940474</td>\n",
       "      <td>0.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.210069</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.943770</td>\n",
       "      <td>0.943767</td>\n",
       "      <td>0.944640</td>\n",
       "      <td>0.943800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "2feaf12ec64400829f53b1a22f3c0637"
     }
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2400, training_loss=0.1568963054815928, metrics={'train_runtime': 1510.5983, 'train_samples_per_second': 165.497, 'train_steps_per_second': 5.177, 'total_flos': 2.01717585035448e+16, 'train_loss': 0.1568963054815928, 'epoch': 3.0690537084398977})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate",
   "id": "9e60a44ba62e7bcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:56:03.717189Z",
     "start_time": "2025-11-10T09:54:26.649222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_predictions_2 = trainer_2.predict(tokenized_test)\n",
    "\n",
    "y_pred_2 = np.argmax(test_predictions_2.predictions, axis=-1)\n",
    "\n",
    "print(\"Test Set Metrics - Case 2:\")\n",
    "print(test_predictions_2.metrics)"
   ],
   "id": "81b7dbb9e9594bcd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "39f60ea29e299e38e76465f01dcbbe8e"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Metrics - Case 2:\n",
      "{'test_loss': 0.22920134663581848, 'test_accuracy': 0.9449, 'test_f1_weighted': 0.9448955415215378, 'test_f1_macro': 0.9448958291653096, 'test_precision': 0.9450545826047639, 'test_recall': 0.9449, 'test_runtime': 97.0582, 'test_samples_per_second': 206.062, 'test_steps_per_second': 6.439}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:56:53.168229Z",
     "start_time": "2025-11-10T09:56:53.163236Z"
    }
   },
   "cell_type": "code",
   "source": "df_results['case_2_pred'] = y_pred_2",
   "id": "7620891e1dd3d295",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:58:02.059808Z",
     "start_time": "2025-11-10T09:58:01.588771Z"
    }
   },
   "cell_type": "code",
   "source": "df_results.to_csv('experiment_results.csv', index=False)",
   "id": "7394a6dad54cdca1",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save Models",
   "id": "8ae32cdc7d8b7e49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:02:55.250375Z",
     "start_time": "2025-11-10T10:02:53.148226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_1.save_model(REPOSITORY_ID_CASE_1)\n",
    "tokenizer.save_pretrained(REPOSITORY_ID_CASE_1)"
   ],
   "id": "80c5432f1c90735c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/roberta-base-finetuned-imdb/tokenizer_config.json',\n",
       " 'models/roberta-base-finetuned-imdb/special_tokens_map.json',\n",
       " 'models/roberta-base-finetuned-imdb/vocab.json',\n",
       " 'models/roberta-base-finetuned-imdb/merges.txt',\n",
       " 'models/roberta-base-finetuned-imdb/added_tokens.json',\n",
       " 'models/roberta-base-finetuned-imdb/tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:03:01.498878Z",
     "start_time": "2025-11-10T10:02:59.416529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_2.save_model(REPOSITORY_ID_CASE_2)\n",
    "tokenizer.save_pretrained(REPOSITORY_ID_CASE_2)"
   ],
   "id": "534232680a0e60de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/roberta-dm-finetuned-imdb/tokenizer_config.json',\n",
       " './models/roberta-dm-finetuned-imdb/special_tokens_map.json',\n",
       " './models/roberta-dm-finetuned-imdb/vocab.json',\n",
       " './models/roberta-dm-finetuned-imdb/merges.txt',\n",
       " './models/roberta-dm-finetuned-imdb/added_tokens.json',\n",
       " './models/roberta-dm-finetuned-imdb/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Case 3",
   "id": "9cf4f97484020eb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Config",
   "id": "a1cdc1a980cf1e2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:10.779890Z",
     "start_time": "2025-11-10T12:13:10.775874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_ID_CASE_3 = \"roberta-base\"\n",
    "REPOSITORY_ID_CASE_3 = f\"./models/roberta-base-mtl-dm-sa\""
   ],
   "id": "be4a47a50879691d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "9761b22ca8707bfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Discourse Markers Loading",
   "id": "dc864bf4ea295d39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:16.391767Z",
     "start_time": "2025-11-10T12:13:14.836683Z"
    }
   },
   "cell_type": "code",
   "source": "df_dm = pd.read_csv(os.path.join('data', 'en.csv'))",
   "id": "81f3be63339243d0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:16.450068Z",
     "start_time": "2025-11-10T12:13:16.439056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dm_to_class_map = {\n",
    "    # == Contrastive Discourse Markers (CDMs) ==\n",
    "    # Show opposition, contrast, concession, or correction\n",
    "    'although': 'CDM',\n",
    "    'but': 'CDM',\n",
    "    'by comparison': 'CDM',\n",
    "    'by contrast': 'CDM',\n",
    "    'conversely': 'CDM',\n",
    "    'however': 'CDM',\n",
    "    'in contrast': 'CDM',\n",
    "    'instead': 'CDM',\n",
    "    'nevertheless': 'CDM',\n",
    "    'nonetheless': 'CDM',\n",
    "    'on the contrary': 'CDM',\n",
    "    'on the other hand': 'CDM',\n",
    "    'otherwise': 'CDM',\n",
    "    'rather': 'CDM',\n",
    "    'regardless': 'CDM',\n",
    "    'still': 'CDM',\n",
    "    'though': 'CDM',\n",
    "    'yet': 'CDM',\n",
    "\n",
    "    # == Elaborative Discourse Markers (EDMs) ==\n",
    "    # Add info, specify, rephrase, give examples, or add speaker stance\n",
    "    'absolutely': 'EDM',\n",
    "    'actually': 'EDM',\n",
    "    'additionally': 'EDM',\n",
    "    'admittedly': 'EDM',\n",
    "    'again': 'EDM',\n",
    "    'also': 'EDM',\n",
    "    'alternately': 'EDM',\n",
    "    'alternatively': 'EDM',\n",
    "    'altogether': 'EDM',\n",
    "    'amazingly': 'EDM',\n",
    "    'and': 'EDM',\n",
    "    'anyway': 'EDM',\n",
    "    'apparently': 'EDM',\n",
    "    'arguably': 'EDM',\n",
    "    'basically': 'EDM',\n",
    "    'besides': 'EDM',\n",
    "    'certainly': 'EDM',\n",
    "    'clearly': 'EDM',\n",
    "    'coincidentally': 'EDM',\n",
    "    'collectively': 'EDM',\n",
    "    'curiously': 'EDM',\n",
    "    'elsewhere': 'EDM',\n",
    "    'especially': 'EDM',\n",
    "    'essentially': 'EDM',\n",
    "    'evidently': 'EDM',\n",
    "    'for example': 'EDM',\n",
    "    'for instance': 'EDM',\n",
    "    'fortunately': 'EDM',\n",
    "    'frankly': 'EDM',\n",
    "    'further': 'EDM',\n",
    "    'furthermore': 'EDM',\n",
    "    'generally': 'EDM',\n",
    "    'happily': 'EDM',\n",
    "    'here': 'EDM',\n",
    "    'honestly': 'EDM',\n",
    "    'hopefully': 'EDM',\n",
    "    'ideally': 'EDM',\n",
    "    'importantly': 'EDM',\n",
    "    'in fact': 'EDM',\n",
    "    'in other words': 'EDM',\n",
    "    'in particular': 'EDM',\n",
    "    'in short': 'EDM',\n",
    "    'in sum': 'EDM',\n",
    "    'incidentally': 'EDM',\n",
    "    'indeed': 'EDM',\n",
    "    'interestingly': 'EDM',\n",
    "    'ironically': 'EDM',\n",
    "    'likewise': 'EDM',\n",
    "    'locally': 'EDM',\n",
    "    'luckily': 'EDM',\n",
    "    'maybe': 'EDM',\n",
    "    'meaning': 'EDM',\n",
    "    'moreover': 'EDM',\n",
    "    'mostly': 'EDM',\n",
    "    'namely': 'EDM',\n",
    "    'nationally': 'EDM',\n",
    "    'naturally': 'EDM',\n",
    "    'notably': 'EDM',\n",
    "    'obviously': 'EDM',\n",
    "    'oddly': 'EDM',\n",
    "    'only': 'EDM',\n",
    "    'optionally': 'EDM',\n",
    "    'or': 'EDM',\n",
    "    'overall': 'EDM',\n",
    "    'particularly': 'EDM',\n",
    "    'perhaps': 'EDM',\n",
    "    'personally': 'EDM',\n",
    "    'plus': 'EDM',\n",
    "    'preferably': 'EDM',\n",
    "    'presumably': 'EDM',\n",
    "    'probably': 'EDM',\n",
    "    'realistically': 'EDM',\n",
    "    'really': 'EDM',\n",
    "    'remarkably': 'EDM',\n",
    "    'sadly': 'EDM',\n",
    "    'separately': 'EDM',\n",
    "    'seriously': 'EDM',\n",
    "    'significantly': 'EDM',\n",
    "    'similarly': 'EDM',\n",
    "    'specifically': 'EDM',\n",
    "    'strangely': 'EDM',\n",
    "    'supposedly': 'EDM',\n",
    "    'surely': 'EDM',\n",
    "    'surprisingly': 'EDM',\n",
    "    'technically': 'EDM',\n",
    "    'thankfully': 'EDM',\n",
    "    'theoretically': 'EDM',\n",
    "    'together': 'EDM',\n",
    "    'truly': 'EDM',\n",
    "    'truthfully': 'EDM',\n",
    "    'undoubtedly': 'EDM',\n",
    "    'unfortunately': 'EDM',\n",
    "    'unsurprisingly': 'EDM',\n",
    "    'well': 'EDM',\n",
    "\n",
    "    # == Implicative Discourse Markers (IDMs) ==\n",
    "    # Show result, consequence, or inference\n",
    "    'accordingly': 'IDM',\n",
    "    'as a result': 'IDM',\n",
    "    'because of that': 'IDM',\n",
    "    'because of this': 'IDM',\n",
    "    'by doing this': 'IDM',\n",
    "    'consequently': 'IDM',\n",
    "    'hence': 'IDM',\n",
    "    'in turn': 'IDM',\n",
    "    'inevitably': 'IDM',\n",
    "    'so': 'IDM',\n",
    "    'thereby': 'IDM',\n",
    "    'therefore': 'IDM',\n",
    "    'thus': 'IDM',\n",
    "\n",
    "    # == Temporal Discourse Markers (TDMs) ==\n",
    "    # Show time or sequence\n",
    "    'afterward': 'TDM',\n",
    "    'already': 'TDM',\n",
    "    'by then': 'TDM',\n",
    "    'currently': 'TDM',\n",
    "    'eventually': 'TDM',\n",
    "    'finally': 'TDM',\n",
    "    'first': 'TDM',\n",
    "    'firstly': 'TDM',\n",
    "    'frequently': 'TDM',\n",
    "    'gradually': 'TDM',\n",
    "    'historically': 'TDM',\n",
    "    'immediately': 'TDM',\n",
    "    'in the end': 'TDM',\n",
    "    'in the meantime': 'TDM',\n",
    "    'increasingly': 'TDM',\n",
    "    'initially': 'TDM',\n",
    "    'lastly': 'TDM',\n",
    "    'lately': 'TDM',\n",
    "    'later': 'TDM',\n",
    "    'meantime': 'TDM',\n",
    "    'meanwhile': 'TDM',\n",
    "    'next': 'TDM',\n",
    "    'normally': 'TDM',\n",
    "    'now': 'TDM',\n",
    "    'occasionally': 'TDM',\n",
    "    'often': 'TDM',\n",
    "    'once': 'TDM',\n",
    "    'originally': 'TDM',\n",
    "    'presently': 'TDM',\n",
    "    'previously': 'TDM',\n",
    "    'recently': 'TDM',\n",
    "    'second': 'TDM',\n",
    "    'secondly': 'TDM',\n",
    "    'simultaneously': 'TDM',\n",
    "    'slowly': 'TDM',\n",
    "    'sometimes': 'TDM',\n",
    "    'soon': 'TDM',\n",
    "    'subsequently': 'TDM',\n",
    "    'suddenly': 'TDM',\n",
    "    'then': 'TDM',\n",
    "    'thereafter': 'TDM',\n",
    "    'third': 'TDM',\n",
    "    'thirdly': 'TDM',\n",
    "    'traditionally': 'TDM',\n",
    "    'typically': 'TDM',\n",
    "    'ultimately': 'TDM',\n",
    "    'usually': 'TDM',\n",
    "}"
   ],
   "id": "cb41f5ad22cb20bf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:16.774922Z",
     "start_time": "2025-11-10T12:13:16.539796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_dm['label'] = [ dm_to_class_map.get(str(dm).lower().strip()) for dm in df_dm.dm ]\n",
    "\n",
    "print(f'Original size: {len(df_dm)}')\n",
    "df_dm = df_dm.loc[df_dm['label'].notnull()].copy()\n",
    "print(f'Size after filtering: {len(df_dm)}')"
   ],
   "id": "bb5a464d2c2978e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 438913\n",
      "Size after filtering: 437346\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Discourse Markers Pre-processing",
   "id": "733db89371614afc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:18.254197Z",
     "start_time": "2025-11-10T12:13:17.098927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset_dm = Dataset.from_pandas(df_dm)\n",
    "dataset_dm = dataset_dm.class_encode_column(\"label\")\n",
    "dataset_dm = dataset_dm.rename_column(\"label\", \"dm_label\")"
   ],
   "id": "e877083d18573bc3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Casting to class labels:   0%|          | 0/437346 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5e2e5788c5d4f70bfe24a7e96ae0efe"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:39.501463Z",
     "start_time": "2025-11-10T12:13:18.410515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Original DM dataset size: {len(dataset_dm)}\")\n",
    "\n",
    "quarter_split = dataset_dm.train_test_split(\n",
    "    test_size=0.75,\n",
    "    seed=42,\n",
    "    stratify_by_column=\"dm_label\"\n",
    ")\n",
    "dataset_dm_quarter = quarter_split['train']\n",
    "\n",
    "print(f\"Reduced DM dataset size (25%): {len(dataset_dm_quarter)}\")"
   ],
   "id": "59a3a11a29afdcd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DM dataset size: 437346\n",
      "Reduced DM dataset size (25%): 109336\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:49.534257Z",
     "start_time": "2025-11-10T12:13:39.661190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer_3 = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "def tokenize_dm(batch):\n",
    "    return tokenizer_3(\n",
    "        batch['s1'],\n",
    "        batch['s2'],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False\n",
    "    )\n",
    "\n",
    "tokenized_dm = dataset_dm_quarter.map(\n",
    "    tokenize_dm,\n",
    "    batched=True,\n",
    "    remove_columns=['s1', 's2', 'dm', 'article_id']\n",
    ")\n",
    "print(f\"DM dataset size: {len(tokenized_dm)}\")"
   ],
   "id": "6680bb85f027fe4b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/109336 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39cb0f565dc544b898e0652662d8ba29"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM dataset size: 109336\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sentiment Analysis",
   "id": "85d7a308982220c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:49.681338Z",
     "start_time": "2025-11-10T12:13:49.675789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_train_sa = raw_train.rename_column(\"label\", \"sa_label\")\n",
    "raw_val_sa = raw_val.rename_column(\"label\", \"sa_label\")"
   ],
   "id": "70a2e0057c77527a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:49.832675Z",
     "start_time": "2025-11-10T12:13:49.769887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_sa(batch):\n",
    "    return tokenizer_3(\n",
    "        batch['text'],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False\n",
    "    )\n",
    "tokenized_train_sa = raw_train_sa.map(tokenize_sa, batched=True, remove_columns=['text'])\n",
    "tokenized_val_sa = raw_val_sa.map(tokenize_sa, batched=True, remove_columns=['text'])\n",
    "\n",
    "print(f\"SA train size: {len(tokenized_train_sa)}\")\n",
    "print(f\"SA val size: {len(tokenized_val_sa)}\")"
   ],
   "id": "2678a04a02961683",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA train size: 25000\n",
      "SA val size: 5000\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Combining Datasets",
   "id": "24cdd8a989ec57c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:49.891172Z",
     "start_time": "2025-11-10T12:13:49.888479Z"
    }
   },
   "cell_type": "code",
   "source": "from datasets import concatenate_datasets, Value",
   "id": "11d7778cce9fc2e7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:49.989466Z",
     "start_time": "2025-11-10T12:13:49.933893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_dm = tokenized_dm.cast_column('dm_label', Value('int64'))\n",
    "tokenized_train_sa = tokenized_train_sa.cast_column('sa_label', Value('int64'))\n",
    "tokenized_val_sa = tokenized_val_sa.cast_column('sa_label', Value('int64'))"
   ],
   "id": "f2d34782689c79f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Casting the dataset:   0%|          | 0/109336 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fae6612b0914233ab370967bc1ac028"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:50.279002Z",
     "start_time": "2025-11-10T12:13:50.068900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IGNORE_INDEX = -100\n",
    "\n",
    "tokenized_dm = tokenized_dm.add_column(\"sa_label\", [IGNORE_INDEX] * len(tokenized_dm))\n",
    "\n",
    "tokenized_train_sa = tokenized_train_sa.add_column(\"dm_label\", [IGNORE_INDEX] * len(tokenized_train_sa))\n",
    "tokenized_val_sa = tokenized_val_sa.add_column(\"dm_label\", [IGNORE_INDEX] * len(tokenized_val_sa))"
   ],
   "id": "ddeac2e60d92ccd4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:50.329656Z",
     "start_time": "2025-11-10T12:13:50.320456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mtl_train_dataset = concatenate_datasets([tokenized_dm, tokenized_train_sa])\n",
    "mtl_val_dataset = concatenate_datasets([tokenized_val_sa])"
   ],
   "id": "9aedd597d8e58dcb",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:50.412572Z",
     "start_time": "2025-11-10T12:13:50.408734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nDatasets concatenated successfully for MTL!\")\n",
    "print(f\"MTL train size: {len(mtl_train_dataset)}\")\n",
    "print(f\"MTL val size: {len(mtl_val_dataset)}\")"
   ],
   "id": "fa054fe97c7a0d65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets concatenated successfully for MTL!\n",
      "MTL train size: 134336\n",
      "MTL val size: 5000\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Metrics",
   "id": "66b5bd1deb15daa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:50.475886Z",
     "start_time": "2025-11-10T12:13:50.470202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics_mtl(eval_pred):\n",
    "    # eval_pred.predictions  agora uma tupla: (logits_dm, logits_sa)\n",
    "    logits_tuple, labels_tuple = eval_pred\n",
    "\n",
    "    # Estamos validando apenas no dataset de SA\n",
    "    logits_sa = logits_tuple[1]\n",
    "    labels_sa = labels_tuple[1]\n",
    "\n",
    "    # Filtrar onde o label no  -100\n",
    "    # (Embora nosso val_set s tenha labels de SA, isso  uma boa prtica)\n",
    "    valid_indices = labels_sa != IGNORE_INDEX\n",
    "    labels = labels_sa[valid_indices]\n",
    "    predictions = np.argmax(logits_sa[valid_indices], axis=-1)\n",
    "\n",
    "    # Reutilizar as mtricas carregadas anteriormente (metric_f1, etc.)\n",
    "    f1_weighted = metric_f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    f1_macro = metric_f1.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    accuracy = metric_accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"f1_weighted\": f1_weighted[\"f1\"],\n",
    "        \"f1_macro\": f1_macro[\"f1\"],\n",
    "    }"
   ],
   "id": "dc3d9130424ae5f9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "7be675a185fca38d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:50.570111Z",
     "start_time": "2025-11-10T12:13:50.558299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import RobertaPreTrainedModel, RobertaModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class RobertaForMultitaskClassification(RobertaPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels_dm = 4\n",
    "        self.num_labels_sa = 2\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "\n",
    "        # --- SEPARATE CLASSIFICATION HEADS ---\n",
    "        # Head 1: Discourse Markers (DM)\n",
    "        self.classifier_dm = nn.Linear(config.hidden_size, self.num_labels_dm)\n",
    "        # Head 2: Sentiment Analysis (SA)\n",
    "        self.classifier_sa = nn.Linear(config.hidden_size, self.num_labels_sa)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        dm_label=None,\n",
    "        sa_label=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # Passing the entrance through RoBERTa's body\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        # Use the [CLS] token output for sorting\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        # Passar o output pelas DUAS cabeas\n",
    "        logits_dm = self.classifier_dm(pooled_output)\n",
    "        logits_sa = self.classifier_sa(pooled_output)\n",
    "\n",
    "        total_loss = 0\n",
    "        loss_fct = CrossEntropyLoss(ignore_index=IGNORE_INDEX)\n",
    "\n",
    "        # Calcular perda (loss) para a tarefa de DM (se os labels existirem)\n",
    "        if dm_label is not None:\n",
    "            loss_dm = loss_fct(logits_dm.view(-1, self.num_labels_dm), dm_label.view(-1))\n",
    "            total_loss += loss_dm\n",
    "\n",
    "        # Calcular perda (loss) para a tarefa de SA (se os labels existirem)\n",
    "        if sa_label is not None:\n",
    "            loss_sa = loss_fct(logits_sa.view(-1, self.num_labels_sa), sa_label.view(-1))\n",
    "            total_loss += loss_sa\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=total_loss,\n",
    "            logits=(logits_dm, logits_sa),\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ],
   "id": "5bd0c05af7071007",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:13:50.881327Z",
     "start_time": "2025-11-10T12:13:50.656572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_3 = AutoConfig.from_pretrained(\"roberta-base\")\n",
    "model_3 = RobertaForMultitaskClassification.from_pretrained(\"roberta-base\", config=config_3)"
   ],
   "id": "4d6258a5eb5207b4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultitaskClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier_dm.bias', 'classifier_dm.weight', 'classifier_sa.bias', 'classifier_sa.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:36:33.686183Z",
     "start_time": "2025-11-10T12:36:33.662150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args_3 = TrainingArguments(\n",
    "    output_dir=REPOSITORY_ID_CASE_3,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1000,\n",
    "    logging_dir=f\"{REPOSITORY_ID_CASE_3}/logs\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=1.0,\n",
    "    fp16=False,\n",
    "    gradient_accumulation_steps=2,\n",
    "\n",
    "    warmup_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"tensorboard\",\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    "\n",
    "    label_names=[\"dm_label\", \"sa_label\"]\n",
    ")"
   ],
   "id": "caf0e35d473c7346",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:36:34.173870Z",
     "start_time": "2025-11-10T12:36:34.159234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_3 = Trainer(\n",
    "    model=model_3,\n",
    "    args=training_args_3,\n",
    "    train_dataset=mtl_train_dataset,\n",
    "    eval_dataset=mtl_val_dataset,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer_3),\n",
    "    compute_metrics=compute_metrics_mtl,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ],
   "id": "e5a9cb900e3149fe",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "b02f43d8ac01ed68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T12:52:53.331921Z",
     "start_time": "2025-11-10T12:36:35.057026Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_3.train()",
   "id": "16dece7858569136",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1106' max='6297' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1106/6297 16:16 < 1:16:30, 1.13 it/s, Epoch 0.53/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.710400</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.941200</td>\n",
       "      <td>0.941166</td>\n",
       "      <td>0.941163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "3db3340a9661724f81f83cfd1a228b90"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrainer_3\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/transformers/trainer.py:2325\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2323\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2324\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2325\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2326\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2327\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2328\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2329\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2330\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/transformers/trainer.py:2618\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2616\u001B[39m update_step += \u001B[32m1\u001B[39m\n\u001B[32m   2617\u001B[39m num_batches = args.gradient_accumulation_steps \u001B[38;5;28;01mif\u001B[39;00m update_step != (total_updates - \u001B[32m1\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m remainder\n\u001B[32m-> \u001B[39m\u001B[32m2618\u001B[39m batch_samples, num_items_in_batch = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_batch_samples\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch_iterator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_batches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2619\u001B[39m \u001B[38;5;66;03m# Store the number of batches for current gradient accumulation\u001B[39;00m\n\u001B[32m   2620\u001B[39m \u001B[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001B[39;00m\n\u001B[32m   2621\u001B[39m \u001B[38;5;28mself\u001B[39m.current_gradient_accumulation_steps = \u001B[38;5;28mlen\u001B[39m(batch_samples)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/transformers/trainer.py:5654\u001B[39m, in \u001B[36mTrainer.get_batch_samples\u001B[39m\u001B[34m(self, epoch_iterator, num_batches, device)\u001B[39m\n\u001B[32m   5652\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_batches):\n\u001B[32m   5653\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m5654\u001B[39m         batch_samples.append(\u001B[38;5;28mnext\u001B[39m(epoch_iterator))\n\u001B[32m   5655\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m   5656\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/accelerate/data_loader.py:579\u001B[39m, in \u001B[36mDataLoaderShard.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    577\u001B[39m     current_batch = send_to_device(current_batch, \u001B[38;5;28mself\u001B[39m.device, non_blocking=\u001B[38;5;28mself\u001B[39m._non_blocking)\n\u001B[32m    578\u001B[39m \u001B[38;5;28mself\u001B[39m._update_state_dict()\n\u001B[32m--> \u001B[39m\u001B[32m579\u001B[39m next_batch = \u001B[38;5;28mnext\u001B[39m(dataloader_iter)\n\u001B[32m    580\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m batch_index >= \u001B[38;5;28mself\u001B[39m.skip_batches:\n\u001B[32m    581\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m current_batch\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:732\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    729\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    730\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    731\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m732\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    733\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    734\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    735\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    736\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    738\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:788\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    786\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    787\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m788\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    789\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    790\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.auto_collation:\n\u001B[32m     49\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset, \u001B[33m\"\u001B[39m\u001B[33m__getitems__\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dataset.__getitems__:\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m         data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     52\u001B[39m         data = [\u001B[38;5;28mself\u001B[39m.dataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2871\u001B[39m, in \u001B[36mDataset.__getitems__\u001B[39m\u001B[34m(self, keys)\u001B[39m\n\u001B[32m   2869\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitems__\u001B[39m(\u001B[38;5;28mself\u001B[39m, keys: \u001B[38;5;28mlist\u001B[39m) -> \u001B[38;5;28mlist\u001B[39m:\n\u001B[32m   2870\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2871\u001B[39m     batch = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[34;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2872\u001B[39m     n_examples = \u001B[38;5;28mlen\u001B[39m(batch[\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(batch))])\n\u001B[32m   2873\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [{col: array[i] \u001B[38;5;28;01mfor\u001B[39;00m col, array \u001B[38;5;129;01min\u001B[39;00m batch.items()} \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_examples)]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2867\u001B[39m, in \u001B[36mDataset.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   2865\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._format_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._format_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[33m\"\u001B[39m\u001B[33marrow\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mpandas\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mpolars\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m   2866\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m Column(\u001B[38;5;28mself\u001B[39m, key)\n\u001B[32m-> \u001B[39m\u001B[32m2867\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2849\u001B[39m, in \u001B[36mDataset._getitem\u001B[39m\u001B[34m(self, key, **kwargs)\u001B[39m\n\u001B[32m   2847\u001B[39m formatter = get_formatter(format_type, features=\u001B[38;5;28mself\u001B[39m._info.features, **format_kwargs)\n\u001B[32m   2848\u001B[39m pa_subtable = query_table(\u001B[38;5;28mself\u001B[39m._data, key, indices=\u001B[38;5;28mself\u001B[39m._indices)\n\u001B[32m-> \u001B[39m\u001B[32m2849\u001B[39m formatted_output = \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2850\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m=\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[32m   2851\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2852\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:658\u001B[39m, in \u001B[36mformat_table\u001B[39m\u001B[34m(table, key, formatter, format_columns, output_all_columns)\u001B[39m\n\u001B[32m    656\u001B[39m python_formatter = PythonFormatter(features=formatter.features)\n\u001B[32m    657\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m658\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    659\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m query_type == \u001B[33m\"\u001B[39m\u001B[33mcolumn\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    660\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m format_columns:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:415\u001B[39m, in \u001B[36mFormatter.__call__\u001B[39m\u001B[34m(self, pa_table, query_type)\u001B[39m\n\u001B[32m    413\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.format_column(pa_table)\n\u001B[32m    414\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m query_type == \u001B[33m\"\u001B[39m\u001B[33mbatch\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m415\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mformat_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:471\u001B[39m, in \u001B[36mPythonFormatter.format_batch\u001B[39m\u001B[34m(self, pa_table)\u001B[39m\n\u001B[32m    469\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.lazy:\n\u001B[32m    470\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m LazyBatch(pa_table, \u001B[38;5;28mself\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m471\u001B[39m batch = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpython_arrow_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mextract_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    472\u001B[39m batch = \u001B[38;5;28mself\u001B[39m.python_features_decoder.decode_batch(batch)\n\u001B[32m    473\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m batch\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dm_project/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:150\u001B[39m, in \u001B[36mPythonArrowExtractor.extract_batch\u001B[39m\u001B[34m(self, pa_table)\u001B[39m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mextract_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa.Table) -> \u001B[38;5;28mdict\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpa_table\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_pydict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# END",
   "id": "ec8ec756114cc0c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
